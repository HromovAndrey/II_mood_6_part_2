{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7882142,"sourceType":"datasetVersion","datasetId":4626328}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/andrey36912/notebookb7111f7b82?scriptVersionId=194419135\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-28T11:37:01.694122Z","iopub.execute_input":"2024-08-28T11:37:01.69461Z","iopub.status.idle":"2024-08-28T11:37:01.70652Z","shell.execute_reply.started":"2024-08-28T11:37:01.694566Z","shell.execute_reply":"2024-08-28T11:37:01.705315Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/technology_data.csv\n/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/sports_data.csv\n/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/education_data.csv\n/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/entertainment_data.csv\n/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/business_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torchtext","metadata":{"execution":{"iopub.status.busy":"2024-08-28T11:37:01.708917Z","iopub.execute_input":"2024-08-28T11:37:01.709369Z","iopub.status.idle":"2024-08-28T11:37:19.347545Z","shell.execute_reply.started":"2024-08-28T11:37:01.709329Z","shell.execute_reply":"2024-08-28T11:37:19.34576Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Collecting torchtext\n  Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext) (4.66.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchtext) (2.32.3)\nRequirement already satisfied: torch>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from torchtext) (2.4.0+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchtext) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (2024.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.3.0->torchtext) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.3.0->torchtext) (1.3.0)\nDownloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: torchtext\nSuccessfully installed torchtext-0.18.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\nfrom sklearn.preprocessing import LabelEncoder\nimport torchtext","metadata":{"execution":{"iopub.status.busy":"2024-08-28T11:37:19.349373Z","iopub.execute_input":"2024-08-28T11:37:19.34979Z","iopub.status.idle":"2024-08-28T11:37:19.857039Z","shell.execute_reply.started":"2024-08-28T11:37:19.349746Z","shell.execute_reply":"2024-08-28T11:37:19.854507Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchtext/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m     _WARN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     20\u001b[0m _TEXT_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/models/text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m _CACHE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_get_torch_home(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchtext/_extension.py:64\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43m_init_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchtext/_extension.py:58\u001b[0m, in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mod_utils\u001b[38;5;241m.\u001b[39mis_module_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext._torchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext C++ Extension is not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibtorchtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchtext/_extension.py:50\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_ops.py:1295\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1290\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m-> 1295\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n","File \u001b[0;32m/opt/conda/lib/python3.10/ctypes/__init__.py:374\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n","\u001b[0;31mOSError\u001b[0m: /opt/conda/lib/python3.10/site-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs"],"ename":"OSError","evalue":"/opt/conda/lib/python3.10/site-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs","output_type":"error"}]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-08-28T11:37:19.858174Z","iopub.status.idle":"2024-08-28T11:37:19.858617Z","shell.execute_reply.started":"2024-08-28T11:37:19.858406Z","shell.execute_reply":"2024-08-28T11:37:19.858427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"technology_df = pd.read_csv(\"/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/technology_data.csv\")\nsports_df = pd.read_csv(\"/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/sports_data.csv\")\neducation_df = pd.read_csv(\"/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/education_data.csv\")\nentertainment_df = pd.read_csv(\"/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/entertainment_data.csv\")\nbusiness_df = pd.read_csv(\"/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/business_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-28T11:37:19.861151Z","iopub.status.idle":"2024-08-28T11:37:19.861638Z","shell.execute_reply.started":"2024-08-28T11:37:19.861414Z","shell.execute_reply":"2024-08-28T11:37:19.861438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"technology_df['labels'] = 'technology'\nsports_df['labels'] = 'sports'\neducation_df['labels'] = 'education'\nentertainment_df['labels'] = 'entertainment'\nbusiness_df['labels'] = 'business'","metadata":{"execution":{"iopub.status.busy":"2024-08-28T11:37:19.863378Z","iopub.status.idle":"2024-08-28T11:37:19.863833Z","shell.execute_reply.started":"2024-08-28T11:37:19.863612Z","shell.execute_reply":"2024-08-28T11:37:19.863636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([technology_df, sports_df, education_df, entertainment_df, business_df], ignore_index=True)\ndf['text'] = df['headlines'].fillna('') + ' ' + df['description'].fillna('') + ' ' + df['content'].fillna('')\ndf.drop(['headlines', 'description', 'content', 'url'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-28T11:37:19.865899Z","iopub.status.idle":"2024-08-28T11:37:19.866419Z","shell.execute_reply.started":"2024-08-28T11:37:19.866178Z","shell.execute_reply":"2024-08-28T11:37:19.866218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-28T11:37:19.867685Z","iopub.status.idle":"2024-08-28T11:37:19.868168Z","shell.execute_reply.started":"2024-08-28T11:37:19.867906Z","shell.execute_reply":"2024-08-28T11:37:19.867929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-28T11:37:19.869643Z","iopub.status.idle":"2024-08-28T11:37:19.870115Z","shell.execute_reply.started":"2024-08-28T11:37:19.869867Z","shell.execute_reply":"2024-08-28T11:37:19.869889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, X, y, max_len=100):\n        self.X = X\n        self.y = y\n        self.max_len = max_len\n        \n        self.label_encoder = LabelEncoder().fit(y)\n        self.vocab = torchtext.vocab.Vectors(\"/kaggle/input/glove6b/glove.6B.50d.txt\")\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        label = self.label_encoder.transform([self.y.iloc[idx]])\n        label = torch.tensor(label)\n        \n        text = self.X.iloc[idx]\n        tokens = text.split()\n        \n        if len(tokens) > self.max_len:\n            tokens = tokens[:self.max_len]\n        else:\n            diff = self.max_len - len(tokens)\n            tokens += ['<pad>'] * diff\n        \n        X = self.vocab.get_vecs_by_tokens(tokens, lower_case_backup=True)\n        \n        return X, label[0]\n\n\ndataset = MyDataset(df['text'], df['labels'])","metadata":{"execution":{"iopub.status.busy":"2024-08-28T11:37:19.871557Z","iopub.status.idle":"2024-08-28T11:37:19.87199Z","shell.execute_reply.started":"2024-08-28T11:37:19.871777Z","shell.execute_reply":"2024-08-28T11:37:19.871799Z"},"trusted":true},"execution_count":null,"outputs":[]}]}